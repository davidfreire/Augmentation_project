{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN performance of a new DataGenerator considering both, the classical Keras augmentation algorithm and albumentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Need to install Keras\n",
    "https://github.com/tensorflow/models/issues/4668\n",
    "conda install python=3.6\n",
    "pip install tensorflow\n",
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../') #to load FileDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FileDataGenerator import FileDataGen \n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator #In order to compare the new class\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, optimizers, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(img_shape):\n",
    "    \n",
    "    entrada = Input(shape=img_shape)\n",
    "    \n",
    "    conv = Conv2D(filters=32, kernel_size=3, activation='relu', name='Conv2D_1')(entrada)\n",
    "    maxpool = MaxPooling2D(pool_size=2, name='Maxpool_1')(conv)\n",
    "    \n",
    "    conv = Conv2D(filters=64, kernel_size=3, activation='relu', name='Conv2D_2')(maxpool)\n",
    "    maxpool = MaxPooling2D(pool_size=2, name='Maxpool_2')(conv)\n",
    "    \n",
    "    conv = Conv2D(filters=128, kernel_size=3, activation='relu', name='Conv2D_3')(maxpool)\n",
    "    maxpool = MaxPooling2D(pool_size=2, name='Maxpool_3')(conv)\n",
    "    \n",
    "    conv = Conv2D(filters=128, kernel_size=3, activation='relu', name='Conv2D_4')(maxpool)\n",
    "    maxpool = MaxPooling2D(pool_size=2, name='Maxpool_4')(conv)\n",
    "    \n",
    "    drop = Dropout(rate=0.5)(maxpool)\n",
    "    \n",
    "    flat = Flatten(name='Flatten')(drop)\n",
    "    dense = Dense(units=512, activation='relu', name='Dense')(flat)\n",
    "    \n",
    "    output = Dense(units=1, activation='sigmoid', name='Output')(dense)\n",
    "    \n",
    "    model = Model(entrada, output)\n",
    "    \n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=1e-4), loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history):\n",
    "    \n",
    "    acc = history['acc']\n",
    "    val_acc = history['val_acc']\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "    \n",
    "    epochs = range(1, len(acc)+1)\n",
    "    \n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation acc')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_Train_Path = '/Users/dfreire/Dropbox/Datasets/small_dataset/train'\n",
    "DB_Val_Path = '/Users/dfreire/Dropbox/Datasets/small_dataset/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_Directory(path):\n",
    "    data=[]\n",
    "    labels=[]\n",
    "    for class_ in os.listdir(path):\n",
    "        dat = [os.path.join(path, class_, img) for img in os.listdir(os.path.join(path, class_))]\n",
    "        lab = [class_ for i in os.listdir(os.path.join(path, class_))]\n",
    "        labels = labels+lab\n",
    "        data = data + dat\n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = Read_Directory(DB_Train_Path)\n",
    "val_data, val_labels = Read_Directory(DB_Val_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training samples: {}'.format(len(train_data)))\n",
    "print('Validation samples: {}'.format(len(val_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical Keras ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range=40,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            horizontal_flip=True)\n",
    "train_datagene = train_datagen.flow_from_directory(\n",
    "    DB_Train_Path,\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagene = val_datagen.flow_from_directory(\n",
    "    DB_Val_Path,\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=get_model([150,150,3])\n",
    "hist = model.fit_generator(train_datagene,\n",
    "                          epochs=2,#100,\n",
    "                          steps_per_epoch=5,#100,\n",
    "                          validation_data = val_datagene,\n",
    "                          validation_steps=50)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(hist.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New FileDataGen --> Reading images not from a Path, but from a list of images (and labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Augmentation -> Classical augmentation (same as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = FileDataGen(rescale=1./255,\n",
    "                      rotation_range=40,\n",
    "                      width_shift_range=0.2,\n",
    "                      height_shift_range=0.2,\n",
    "                      shear_range=0.2,\n",
    "                      zoom_range=0.2,\n",
    "                      horizontal_flip=True)\n",
    "\n",
    "train_datagene = train_datagen.flow_from_filelist(train_data,\n",
    "                                      train_labels,\n",
    "                                      target_size=(150,150),\n",
    "                                      batch_size=32,\n",
    "                                      class_mode='binary')\n",
    "\n",
    "val_datagen = FileDataGen(rescale=1./255)\n",
    "\n",
    "train_datagene = val_datagen.flow_from_filelist(val_data,\n",
    "                                      val_labels,\n",
    "                                      target_size=(150,150),\n",
    "                                      batch_size=32,\n",
    "                                      class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=get_model([150,150,3])\n",
    "hist = model.fit_generator(train_datagene,\n",
    "                          epochs=100,\n",
    "                          steps_per_epoch=100,\n",
    "                          validation_data = val_datagene,\n",
    "                          validation_steps=50)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Augmentation -> Albumentations --> ShiftScaleRotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = FileDataGen(rescale=1./255,\n",
    "                      aug_mode = 'ShiftScaleRotate')\n",
    "\n",
    "\n",
    "train_datagene = train_datagen.flow_from_filelist(train_data,\n",
    "                                      train_labels,\n",
    "                                      target_size=(150,150),\n",
    "                                      batch_size=32,\n",
    "                                      class_mode='binary')\n",
    "\n",
    "val_datagen = FileDataGen(rescale=1./255)\n",
    "\n",
    "train_datagene = val_datagen.flow_from_filelist(val_data,\n",
    "                                      val_labels,\n",
    "                                      target_size=(150,150),\n",
    "                                      batch_size=32,\n",
    "                                      class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=get_model([150,150,3])\n",
    "hist = model.fit_generator(train_datagene,\n",
    "                          epochs=100,\n",
    "                          steps_per_epoch=100,\n",
    "                          validation_data = val_datagene,\n",
    "                          validation_steps=50)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Augmentation -> Albumentations --> IAAPerspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = FileDataGen(rescale=1./255,\n",
    "                      aug_mode = 'IAAPerspective')\n",
    "\n",
    "train_datagene = train_datagen.flow_from_filelist(train_data,\n",
    "                                      train_labels,\n",
    "                                      target_size=(150,150),\n",
    "                                      batch_size=32,\n",
    "                                      class_mode='binary')\n",
    "\n",
    "val_datagen = FileDataGen(rescale=1./255)\n",
    "\n",
    "train_datagene = val_datagen.flow_from_filelist(val_data,\n",
    "                                      val_labels,\n",
    "                                      target_size=(150,150),\n",
    "                                      batch_size=32,\n",
    "                                      class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=get_model([150,150,3])\n",
    "hist = model.fit_generator(train_datagene,\n",
    "                          epochs=100,\n",
    "                          steps_per_epoch=100,\n",
    "                          validation_data = val_datagene,\n",
    "                          validation_steps=50)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Augmentation -> Albumentations --> MediumAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = FileDataGen(rescale=1./255,\n",
    "                      aug_mode = 'MediumAug')\n",
    "\n",
    "train_datagene = train_datagen.flow_from_filelist(train_data,\n",
    "                                      train_labels,\n",
    "                                      target_size=(150,150),\n",
    "                                      batch_size=32,\n",
    "                                      class_mode='binary')\n",
    "\n",
    "val_datagen = FileDataGen(rescale=1./255)\n",
    "\n",
    "train_datagene = val_datagen.flow_from_filelist(val_data,\n",
    "                                      val_labels,\n",
    "                                      target_size=(150,150),\n",
    "                                      batch_size=32,\n",
    "                                      class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=get_model([150,150,3])\n",
    "hist = model.fit_generator(train_datagene,\n",
    "                          epochs=100,\n",
    "                          steps_per_epoch=100,\n",
    "                          validation_data = val_datagene,\n",
    "                          validation_steps=50)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Augmentation -> Albumentations --> StrongAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = FileDataGen(rescale=1./255,\n",
    "                      aug_mode = 'StrongAug')\n",
    "\n",
    "train_datagene = train_datagen.flow_from_filelist(train_data,\n",
    "                                      train_labels,\n",
    "                                      target_size=(150,150),\n",
    "                                      batch_size=32,\n",
    "                                      class_mode='binary')\n",
    "\n",
    "val_datagen = FileDataGen(rescale=1./255)\n",
    "\n",
    "train_datagene = val_datagen.flow_from_filelist(val_data,\n",
    "                                      val_labels,\n",
    "                                      target_size=(150,150),\n",
    "                                      batch_size=32,\n",
    "                                      class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=get_model([150,150,3])\n",
    "hist = model.fit_generator(train_datagene,\n",
    "                          epochs=100,\n",
    "                          steps_per_epoch=100,\n",
    "                          validation_data = val_datagene,\n",
    "                          validation_steps=50)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(hist.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
